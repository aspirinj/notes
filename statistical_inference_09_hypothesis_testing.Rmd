---
title: "Inference09 - Hypothesis"
author: "Howard J, based on the work of Caffo"
date: "December 10, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE}
library(UsingR)
library(tidyverse)
```


## Hypothesis testing
Classical Hypothesis testing is concerned with deciding between two decisions. The null hypothesis is assumed true and statistical evidence is required to reject it.  

* $H_0$: Null hypothesis is specified that represents the status quo.  
* $H_a$: Alternative hypothesis is what we require evidence to conclude.  



*Example:* A RDI (respiratory disturbance index) of more than $30$ events / hour, say, is considered evidence of severe SDB (sleep disordered breathing). Suppose that in a sample of $100$ overweight subjects with other risk factors for SDB at a sleep clinic, the mean RDI was $32$ events / hour with a standard deviation of $10$ events / hour. We might want to test the hypothesis that:  

* $H_0 : \mu = 30$  
* $H_a : \mu > 30$f  
where $\mu$ is the population mean RDI.


### Hypothesis testing
The alternative hypotheses are typically of the form $<$, $>$ or $\neq$.   
Two types of errors:  

| Truth | Decide | Result | Comments | Cause |
| ---|---|---|---|--- |
| $H_0$ | $H_a$ | Type I error | innocent people convicted | low standard |
| $H_a$ | $H_0$ | Type II error | guilty people let free | high standard |


$\alpha$: Type I error rate. The Probability of rejecting the null hypothesis when, in fact, the null hypothesis is correct.   
$\beta$: Type II error rate. The Probability of the failure of rejecting the null hypothesis when, in fact, the null hypothesis is false.   

Hypothesis testing strategy would reject the null hypothesis if $\bar X$ was larger than constant $C$. Typically, $C$ is usually chosen so that $\alpha = 0.05$.

Using Z-score if the sample size is large enough, which is how many standard errors the sample mean is above the hypothesized mean, the 95th percentile of a normal distribution is 1.645 standard deviations from the mean.

$$Z_{1-\alpha} = \frac{C - \mu_0}{S / \sqrt{n}}$$
Thus, $C = \mu_0 + Z_{1-\alpha} * {s \over \sqrt{n}}$.


*Example:* Assume standard error of the mean $10 / \sqrt{100} = 1$

* Under $H_0$ $\bar X \sim N(30, 1)$ according to CTL.  
* z = $\frac{32 - 30}{10 / \sqrt{100}} = 2$ is greater than $1.645$.  
* $P(\bar X > C; H_0)=0.05$; $C = 30 + 1 \times 1.645 = 31.645$  



### General rules
The general rules for the three most important alternatives; the $Z$ test for $H_0:\mu = \mu_0$ versus  
  - H_1: $\mu < \mu_0$  
  - H_2: $\mu \neq \mu_0$  
  - H_3: $\mu > \mu_0$  

*TS* (Test statistic):  
$$TS = \frac{\bar{X} - \mu_0}{S / \sqrt{n}}$$  

Reject the null hypothesis for the three alternatives when:  
* $TS \leq Z_{\alpha} = -Z_{1 - \alpha}$
* $|TS| \geq Z_{1 - \alpha / 2}$
* $TS \geq Z_{1 - \alpha}$


### Notes
* We have not fixed the probability of a type II error, $\beta$; therefore we tend to say Fail to reject $H_0$ rather than accepting $H_0$.  
* Statistical significance is no the same as scientific significance.  
* The region of *TS* values for which you reject $H_0$ is called the **rejection region**.  
* The probability of rejecting the null hypothesis when it is false is called **power**
* Power is a used a lot to calculate sample sizes for experiments



### T test
The $Z$ test requires the assumptions of the CLT and for $n$ to be large enough for it to apply. If $n$ is small, then a Gossett's $T$ test is performed exactly in the same way, with the normal quantiles replaced by the appropriate Student's $T$ quantiles and $n-1$ df.  

*Example:* suppose that $n=16$ (rather than $100$). The t statistic:    
$$\frac{\bar X - 30}{s / \sqrt{16}}$$  
follows a $T$ distribution with 15 df under $H_0$.  

Under $H_0$, the probability that it is larger that the 95th percentile of the $T$ distribution is 5%. The 95th percentile of the T distribution with 15 df is `qt(.95, 15)`, calculated as `r qt(.95, 15)`. So that our test statistic is now $\sqrt{16}(32 - 30) / 10 = 0.8$, which is smaller than `r qt(.95, 15)`. Fail to reject $H_0$.  


### Two sided tests
Suppose that we would reject the null hypothesis $H_0$ if in fact the mean was too large or too small. That is, we want to test the alternative $H_a : \mu \neq 30$. We want the probability of rejecting under the null to be 5%, split equally as 2.5% in the upper tail and 2.5% in the lower tail.  

Thus we reject if our test statistic is larger than `qt(.975, 15)` or smaller than `qt(.025, 15)`. This is the same as saying: reject if the absolute value of our statistic is larger than `qt(0.975, 15)` = `r qt(0.975, 15)`. So we fail to reject the two sided test as well, since test statistic, 0.8 < `r qt(0.975, 15)` as in our example. (If you fail to reject the one sided test, you know that you will fail to reject the two sided)


*Example:* the observations are paired. To test whether the difference in the heights is zero or non-zero.    
```{r}
data(father.son)
str(father.son)
t.test(father.son$sheight - father.son$fheight) # Inputs for T test: numeric array
```

### Connections with confidence intervals
* Consider testing $H_0: \mu = \mu_0$ versus $H_a: \mu \neq \mu_0$
* Take the set of all possible values for which you fail to reject $H_0$, this set is a $(1-\alpha)100\%$ confidence interval for $\mu$
* The same works in reverse; if a $(1-\alpha)100\%$ interval
  contains $\mu_0$, then we *fail  to* reject $H_0$

### Two group intervals
- First, now you know how to do two group T tests
since we already covered indepedent group T intervals
- Rejection rules are the same
- Test $H_0 : \mu_1 = \mu_2$
- Let's just go through an example

### `chickWeight` data
Recall that we reformatted this data
```{r, echo=TRUE,results='hide'}
library(datasets); data(ChickWeight); library(reshape2)
##define weight gain or loss
wideCW <- dcast(ChickWeight, Diet + Chick ~ Time, value.var = "weight")
names(wideCW)[-(1 : 2)] <- paste("time", names(wideCW)[-(1 : 2)], sep = "")
library(dplyr)
wideCW <- mutate(wideCW,
  gain = time21 - time0
)
```

---
### Unequal variance T test comparing diets 1 and 4
```{r,echo=TRUE, comment="> ", results='markup'}
wideCW14 <- subset(wideCW, Diet %in% c(1, 4))
t.test(gain ~ Diet, paired = FALSE,
       var.equal = TRUE, data = wideCW14)
```

*Exact binomial test:* Recall this problem, *Suppose a friend has $8$ children, $7$ of which are girls and none are twins*? Perform the relevant hypothesis test. $H_0 : p = 0.5$ $H_a : p > 0.5$. What is the relevant rejection region so that the probability of rejecting is (less than) 5%?  

Rejection region | Type I error rate |
---|---|
[0 : 8] | `r pbinom(-1, size = 8, p = .5, lower.tail = FALSE)`
[1 : 8] | `r pbinom( 0, size = 8, p = .5, lower.tail = FALSE)`
[2 : 8] | `r pbinom( 1, size = 8, p = .5, lower.tail = FALSE)`
[3 : 8] | `r pbinom( 2, size = 8, p = .5, lower.tail = FALSE)`
[4 : 8] | `r pbinom( 3, size = 8, p = .5, lower.tail = FALSE)`
[5 : 8] | `r pbinom( 4, size = 8, p = .5, lower.tail = FALSE)`
[6 : 8] | `r pbinom( 5, size = 8, p = .5, lower.tail = FALSE)`
[7 : 8] | `r pbinom( 6, size = 8, p = .5, lower.tail = FALSE)`
[8 : 8] | `r pbinom( 7, size = 8, p = .5, lower.tail = FALSE)`

---
## Notes
* It's impossible to get an exact 5% level test for this case due to the discreteness of the binomial.
  * The closest is the rejection region [7 : 8]
  * Any alpha level lower than `r 1 / 2 ^8` is not attainable.
* For larger sample sizes, we could do a normal approximation, but you already knew this.
* Two sided test isn't obvious.
  * Given a way to do two sided tests, we could take the set of values of $p_0$ for which we fail to reject to get an exact binomial confidence interval (called the Clopper/Pearson interval, BTW)
* For these problems, people always create a P-value (next lecture) rather than computing the rejection region.
