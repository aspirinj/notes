---
title: "Statistical Inference Notes"
author: "Howard J"
date: "December 10, 2017"
output:
html_document:
  highlight: pygments
  theme: spacelab
  toc: yes
header-includes: \usepackage{graphicx}
---

```{r message=FALSE, warning=FALSE}
library(UsingR)
library(tidyverse)
library(grid)
library(png)
library(manipulate)
```


## Expected Values
__Expected Values__, including __Mean__, __Variance__, __Skewness__, etc. characterize a distribution.  
__Mean__ characterizes of the center of a density or mass function.  
__Variance__ characterizes how spread out the distribution is.  
__Skewness__ considers how much a density is pulled toward high or low values.  
*Note:* in this part we are discussing __Population__ quantities. Using sample analogs to estimate the associated population quantities.  


### Population Mean   
The expected value or population mean of a random variable is the center of its distribution.  

For Discrete random variables $X$ with PMF $p(x)$, the population mean is defined as:  
$$
E[X] = \sum_{x} xp(x)
$$  
where the sum is taken over all possible values of $x$. The idea is taken from the physical idea of the center of mass. Specifically, $E[X]$ represent the center of mass of a collection of locations and weights, $\{x,p(x)\}$. We can exploit this fact to quickly calculate population means for distributions where the center of mass is obvious.  


### Sample Mean   
It is important to contrast the population mean (the estimand) with the sample mean (the estimator). The sample mean estimates the population mean. Not coincidentally, since the population mean is the center of mass of the population distribution, the sample mean is the center of mass of the data.  
$$
\bar X = \sum_{i=1}^n x_i p(x_i),
$$  

where $p(x_i) = 1/n$.

#### Example: 
Galton's tabulated data used to study the relationship between a parent's height and their childrens. The data were tabulated and consequently made discrete.  

```{r load galton}
data(galton)
tail(galton)
```

```{r}
longGalton <- gather(galton, key = person_attr, value = measurement, child, parent)
g <- ggplot(longGalton, aes(x = measurement, y = ..density..)) + 
  geom_histogram(aes(fill = person_attr), binwidth=1, color = "black") + 
  geom_density(size = 2) +
  facet_grid(. ~ person_attr)
g
```


#### Example: 
Suppose that a die is rolled and $X$ is the number face up. What is the expected value of $X$?  
```{r, fig.align='center', fig.height=4, fig.width=10}
ggplot(data.frame(x_val=factor(1:6), y_val=rep(1/6,6)), aes(x=x_val, y=y_val)) + 
  geom_bar(stat="identity", colour = 'black', fill = "lightblue")
```


### Facts about expected values  
Recall that expected values are properties of *population* distributions. The expected value, or *mean*, height is *the center of the population density* of heights.  

The average of ten randomly sampled people's height is itself a random variable. What does the distribution of averages look like?.  

Consider the die rolls again. If wanted to know the distribution of averages of 100 die rolls, you could (at least in principle) roll 100 dice, take the average and repeat that process. Imagine, if you could only roll the 100 dice once. Then we would have direct information about the distribution of die rolls (since we have 100 of them), but we wouldn't have any direct information about the distribution of the average of 100 die rolls, since we only observed one average.  

Fortunately, the mathematics tells us about that distribution. *The distribution of the estimator (the sample mean) is centered at the distribution of what it's estimating (the population mean)*. When the expected value of an estimator is what its trying to estimate, we say that the estimator is *unbiased*.  


### Simulation experiments  
__Standard normals__   
Consider simulating lots of *standard normals* and plotting a histogram (the blue density). Now consider simulating lots of *averages of 10 standard normals* and plotting their histogram (the salmon colored density). Notice that both of them are centered in the same spot. The simulation of average of multiple random variables more concentrated around that point.  

Simulating normals with $mean=0$ and $var=1$ versus averages of 10 normals from the same population.  
```{r, fig.height=6, figh.width=6, fig.align='center'}
sim_count <- 10000
sample_size <- 10
df <- data.frame(
    sim_val=c(rnorm(sim_count), apply(matrix(rnorm(sim_count*sample_size), sim_count), 1, mean)),
    type=factor(rep(c("Obs", "Mean"), c(sim_count, sim_count))) 
    )
ggplot(df, aes(x = sim_val, fill = type)) + 
  geom_density(size = 2, alpha = .2); 
```

Simulating exponential distribution with $\lambda=0.2$ versus averages of 40 exponential from the same population:  
```{r}
lambda <- 0.2
sim_count <- 1000
sample_size <- 40
df <- data.frame(
    sim_val=c(rexp(sim_count,lambda), apply(matrix(rexp(sim_count*sample_size,lambda), sim_count), 1, mean)),
    type=factor(rep(c("Obs", "Mean"), c(sim_count, sim_count))) 
    )
ggplot(df, aes(x = sim_val, fill = type)) + 
  geom_density(size = 2, alpha = .2)
```


__Averages of x die rolls__
Consider rolling a die a lot of times and taking a histogram of the results, that's the left most plot. The bars are equally distributed at the six possible outcomes and thus the histogram is centered around 3.5. Now consider simulating lots of averages of 2 dice. Its histogram is also centered at 3.5. So is it for 3 and 4. Notice also the distribution gets increasing Gaussian looking (like a bell curve) and increasingly concentrated around 3.5.  

```{r, fig.align='center',fig.height=5, fig.width=10}  
df <- data.frame(
  sim_val = c(sample(1:6, sim_count, replace = TRUE),
        apply(matrix(sample(1:6, sim_count*2, replace = TRUE), sim_count), 1, mean), # avg, 2 dice
        apply(matrix(sample(1:6, sim_count*3, replace = TRUE), sim_count), 1, mean), # avg, 3 dice
        apply(matrix(sample(1:6, sim_count*4, replace = TRUE), sim_count), 1, mean)  # avg, 4 dice
        ),
  sample_size = factor(rep(1 : 4, rep(sim_count, 4))))
g <- ggplot(df, aes(x = sim_val, fill = sample_size)) + geom_histogram(alpha = .20, binwidth=.25, colour = "black") 
g + facet_grid(. ~ sample_size)
```


__Averages of x coin flips__  
The same. All of the distributions are centered around 0.5.  
```{r, fig.align='center',fig.height=5, fig.width=10}
df <- data.frame(
  sim_val = c(sample(0:1, sim_count, replace = TRUE),
        apply(matrix(sample(0:1, sim_count*10, replace = TRUE), sim_count), 1, mean),
        apply(matrix(sample(0:1, sim_count*20, replace = TRUE), sim_count), 1, mean),
        apply(matrix(sample(0:1, sim_count*30, replace = TRUE), sim_count), 1, mean)
        ),
  sample_size = factor(rep(c(1, 10, 20, 30), rep(sim_count, 4))))
g <- ggplot(df, aes(x = sim_val, fill = sample_size)) + geom_histogram(alpha = .20, binwidth = 1 / 12, colour = "black"); 
g + facet_grid(. ~ sample_size)
```


### Summary notes  
- Expected values are properties of distributions.
- The population mean is the center of mass of population.
- The sample mean is the center of mass of the observed data.
- The sample mean is an estimate of the population mean.
- The sample mean is unbiased: the population mean of its distribution is the mean that it's  trying to estimate.
- The more data that goes into the sample mean, the more concentrated its density / mass function is around the population mean.


